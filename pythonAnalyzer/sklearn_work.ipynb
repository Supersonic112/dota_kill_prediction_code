{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn, numpy\n",
    "import itertools\n",
    "import json_helper_functions as jshf\n",
    "import csv\n",
    "import sys, os, re, time, math, logging\n",
    "from sklearn.utils import Bunch\n",
    "from sklearn.model_selection import train_test_split, validation_curve, learning_curve, ShuffleSplit\n",
    "from sklearn.metrics import f1_score, precision_recall_curve, regression, average_precision_score, precision_score, recall_score, confusion_matrix\n",
    "import pickle\n",
    "## classifiers\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "#### GLOBAL VARIABLES\n",
    "# activate test outputs (untested)\n",
    "TEST = False\n",
    "global_version = \"8e\"\n",
    "csvpath=\"/../dota/csv/\"\n",
    "# create a result dict that contains all classification results of the current session\n",
    "if not 'resultdict' in globals():\n",
    "\tresultdict={}\n",
    "### logging ###\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.addHandler(logging.NullHandler())\n",
    "logger.setLevel(logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def importCsvFile(filepath, filename, append_target_names = False, data_version = global_version):\n",
    "\twith open(filepath+filename,'r') as csvfile:\n",
    "\t\tcontents = csv.reader(csvfile)\n",
    "\t\ttemp = next(contents)\n",
    "\t\tn_features = int(temp[0]) - 1 # -1 because of the target/evaluation value\n",
    "\t\tn_samples = int(temp[1])\n",
    "\t\tversion = temp[2]\n",
    "\t\tassert version == data_version, \"file has version {}, but the wanted version is {}!\".format(version, data_version)\n",
    "\t\ttarget_feature_name = temp[3]\n",
    "\t\tttargets = ['Dead', 'Alive']\n",
    "\t\ttfeatures = next(contents)\n",
    "\t\ttfeature_types = next(contents)# not currently used, everything is a float\n",
    "\t\tdtypes = []\n",
    "\t\ttarget_feature_column = tfeatures.index(target_feature_name)\n",
    "\t\ttfeatures.pop(target_feature_column)\n",
    "\t\ttarget_feature_type = tfeature_types.pop(target_feature_column)\n",
    "\t\tdata = numpy.empty((n_samples, n_features), dtype=numpy.float64)\n",
    "\t\ttarget = numpy.empty((n_samples,), dtype=numpy.bool)\n",
    "\t\tfor i, ir in enumerate(contents):\n",
    "\t\t\t# take target value away first\n",
    "\t\t\ttarget_val = ir.pop(target_feature_column)\n",
    "\t\t\ttarget[i] = numpy.asarray(target_val=='True', dtype=numpy.bool)\n",
    "\t\t\t# then take the rest of the features\n",
    "\t\t\tdata[i] = numpy.asarray(ir, dtype=numpy.float64)\n",
    "\t\tif append_target_names:\n",
    "\t\t\ttarget_names = numpy.array(ttargets)\n",
    "\t\t\tfeature_names = numpy.array(tfeatures)\n",
    "\t\tif append_target_names:\n",
    "\t\t\treturn data, target, feature_names, target_names, version\n",
    "\t\telse:\n",
    "\t\t\treturn data, target, version\n",
    "\n",
    "def checkFileVersion(filepath, wanted_version = global_version):\n",
    "\twith open(filepath,'r') as csvfile:\n",
    "\t\tcontents = csv.reader(csvfile)\n",
    "\t\ttemp = next(contents)\n",
    "\t\tversion = temp[2]\n",
    "\t\treturn version == wanted_version\n",
    "\n",
    "if TEST:\n",
    "\tprint(importCsvFile(csvpath, \"2155844500-8.csv\", True, \"8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create cache\n",
    "if not 'csv_import_cache' in globals():\n",
    "\tglobal csv_import_cache\n",
    "\tcsv_import_cache = {}\n",
    "# import CSVs\n",
    "def csvImport(filepath, filename_regex=\"[0-9]*[-][0-9]*[a-z]*[.]csv$\", return_X_y=False, wanted_version=global_version, force_reload=True, ignore_features=None):\n",
    "\tdata, target, target_names, feature_names, number_of_files = (None, None, None, None, None)\n",
    "\tif not force_reload and csv_import_cache.get(wanted_version):\n",
    "\t\tdata, target, target_names, feature_names, number_of_files = csv_import_cache.get(wanted_version)\n",
    "\t\tprint(\"fetched data of {} files from cache\".format(number_of_files))\n",
    "\telse:\n",
    "\t\t# initialize array with the first fitting file in the directory\n",
    "\t\tfirstfile = \"\"\n",
    "\t\tfor examplefile in os.listdir(filepath):\n",
    "\t\t\tif os.path.isfile(filepath+examplefile) and checkFileVersion(filepath+examplefile, wanted_version):\n",
    "\t\t\t\tfirstfile = examplefile\n",
    "\t\t\t\tlogger.debug(\"getting metadata from file\",examplefile)\n",
    "\t\t\t\tbreak\n",
    "\t\tif firstfile == \"\":\n",
    "\t\t\traise FileNotFoundError(\"no file of version {} found in the directory {}\".format(wanted_version,filepath))\n",
    "\t\tdata, target, feature_names, target_names, global_version = importCsvFile(filepath, firstfile, data_version=wanted_version, append_target_names=True)\n",
    "\t\tnumber_of_files = 0\n",
    "\t\tfor elem in os.listdir(filepath):\n",
    "\t\t\tif not re.match(filename_regex, elem):\n",
    "\t\t\t\tlogger.debug(\"filename regex did not match \"+elem)\n",
    "\t\t\t\tcontinue\n",
    "\t\t\tlogger.info(\"reading file\",elem)\n",
    "\t\t\tif not checkFileVersion(filepath+elem, wanted_version):\n",
    "\t\t\t\tcontinue\n",
    "\t\t\tnewdata, newtarget, file_version = importCsvFile(filepath, elem, data_version=wanted_version)\n",
    "\t\t\t# append new stuff\n",
    "\t\t\tdata = numpy.append(data, newdata, axis=0)\n",
    "\t\t\ttarget = numpy.append(target, newtarget, axis=0)\n",
    "\t\t\tnumber_of_files += 1\n",
    "\t\tcsv_import_cache.update({wanted_version:(data, target, target_names, feature_names, number_of_files)})\n",
    "\tif not ignore_features is None:\n",
    "\t\tignore_feature_list = []\n",
    "\t\tdata = data[:,[n for n in numpy.arange(len(feature_names)) if feature_names[n] not in ignore_features]]\n",
    "\t\tfeature_names = feature_names[[n for n in numpy.arange(len(feature_names)) if feature_names[n] not in ignore_features],]\n",
    "\tif return_X_y:\n",
    "\t\treturn (data, target)\n",
    "\tprint(\"loaded {} files\".format(number_of_files))\n",
    "\treturn Bunch(data=data, target=target, target_names=target_names, feature_names=feature_names)\n",
    "\t\t\t\t# [\"name\", \"maxHealth\", \"curHealth\", \"posX\", \"posY\", \"gold\", \"xp\", \"level\", \"team\", \"lastDamage\"])\n",
    "\n",
    "if TEST:\n",
    "\tdota_alldata = csvImport(csvpath, wanted_version=\"8e\", force_reload=False)\n",
    "\tdota_data = dota_alldata.get(\"data\")\n",
    "\tdota_target = dota_alldata.get(\"target\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printDataProperties(alldata):\n",
    "\tdata_only = alldata.get(\"data\")\n",
    "\ttarget_only = alldata.get(\"target\")\n",
    "\tprint(\"Data set properties: {} True elements, {} False elements\".format(len([t for t in dota_target if t]), len([t for t in dota_target if not t])))\n",
    "\n",
    "def printTrainTestSetShape(X, y):\n",
    "\tprint(\"data set shape: {}\\nTrue/False ratio:{}\".format(X.shape, str(len([t for t in y if t]))+\":\"+str(len([t for t in y if not t]))))\n",
    "\n",
    "if TEST:\n",
    "\talldata = csvImport(csvpath, wanted_version=\"3k\", force_reload=False)\n",
    "\tprintDataProperties(alldata)\n",
    "\tdata_only = alldata.get(\"data\")\n",
    "\ttarget_only = alldata.get(\"target\")\n",
    "\tX_training, X_test, y_training, y_test = train_test_split(data_only, target_only, train_size=0.3, random_state=42)\n",
    "\tprintTrainTestSetShape(X_training, y_training)\n",
    "\tprintTrainTestSetShape(X_test, y_test)\n",
    "\tprint(numpy.unique(dota_target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def trainclf(inpclf, inpdata, collect_infos=False):\n",
    "\tX_training, y_training = inpdata\n",
    "\tstarttime = time.time()\n",
    "\tprint(\"Training classifier {}, start time: {}\".format(str(inpclf),time.ctime()))\n",
    "\tfitclf = inpclf.fit(X_training, y_training)\n",
    "\tendtime = time.time()\n",
    "\tprint(\"end:\",time.ctime())\n",
    "\tif collect_infos:\n",
    "\t\treturn fitclf, {\"training time\":endtime-starttime}\n",
    "\treturn fitclf\n",
    "if TEST:\n",
    "\tdcfitclf = trainclf(clf, (X_training, y_training))\n",
    "\tknnfitclf = trainclf(KNeighborsClassifier(3), (X_training, y_training))\n",
    "\t#rffitclf=trainclf(RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1), (X_training, y_training))\n",
    "\tabfitclf=trainclf(AdaBoostClassifier(), (X_training, y_training))\n",
    "\tdtfitclf=trainclf(DecisionTreeClassifier(), (X_training, y_training))\n",
    "\tmlpfitclf = trainclf(MLPClassifier(max_iter=200, hidden_layer_sizes=(20,100,50,10)), (X_training, y_training))\n",
    "\t#fitclf = clf.fit(X_training, y_training)\n",
    "\t#gpfitclf = gpclf.fit(X_training, y_training)\n",
    "\t#rffitclf = rfclf.fit(X_training, y_training)\n",
    "\t#abfitclf = abclf.fit(X_training, y_training)\n",
    "\t#dcfitclf = dcclf.fit(X_training, y_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copied from http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, numpy.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = numpy.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copied from http://scikit-learn.org/stable/auto_examples/model_selection/plot_learning_curve.html\n",
    "def plot_learning_curve(estimator, title, X, y, ylim=None, cv=None,\n",
    "\t\t\t\t\t\tn_jobs=1, train_sizes=numpy.linspace(.1, 1.0, 5)):\n",
    "\tplt.figure()\n",
    "\tplt.title(title)\n",
    "\tif ylim is not None:\n",
    "\t\tplt.ylim(*ylim)\n",
    "\tplt.xlabel(\"Training examples\")\n",
    "\tplt.ylabel(\"Score\")\n",
    "\ttrain_sizes, train_scores, test_scores = learning_curve(\n",
    "\t\testimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes)\n",
    "\ttrain_scores_mean = numpy.mean(train_scores, axis=1)\n",
    "\ttrain_scores_std = numpy.std(train_scores, axis=1)\n",
    "\ttest_scores_mean = numpy.mean(test_scores, axis=1)\n",
    "\ttest_scores_std = numpy.std(test_scores, axis=1)\n",
    "\tplt.grid()\n",
    "\tplt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "\t\t\t\t\t\ttrain_scores_mean + train_scores_std, alpha=0.1,\n",
    "\t\t\t\t\t\tcolor=\"r\")\n",
    "\tplt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "\t\t\ttest_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
    "\t#plt.tight_layout()\n",
    "\tplt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n",
    "\t\t\tlabel=\"Training score\")\n",
    "\tplt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n",
    "\t\t\tlabel=\"Cross-validation score\")\n",
    "\tplt.legend(loc=\"best\")\n",
    "\treturn plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scoreclf(inpclf, inpdata, collect_infos = False, class_names=None, clfname=None):\n",
    "\tX_test, y_test = inpdata\n",
    "\tfitstarttime = time.ctime()\n",
    "\tprint(\"scoring start:\",fitstarttime)\n",
    "\tfitclfscore = inpclf.score(X_test, y_test)\n",
    "\ty_pred = inpclf.predict(X_test)\n",
    "\tclf_score = f1_score(y_test, y_pred, average=None, labels=[True, False])\n",
    "\tfitendtime = time.ctime()\n",
    "\tprint(\"scoring end:\",fitendtime)\n",
    "\tif collect_infos:\n",
    "\t\tinfos = {\"test data size\":len(y_test), \"F1 score True\":clf_score[0],\"F1 score False\":clf_score[1]}\n",
    "\tprint(\"{}: score {}, deviation {}\".format(str(inpclf), clf_score, fitclfscore.std()*2))\n",
    "\tzippedlist = list(zip(y_pred,y_test))\n",
    "\ttruepositive = len([1 for elem in zippedlist if elem == (True,True)])\n",
    "\ttruenegative = len([1 for elem in zippedlist if elem == (False,False)])\n",
    "\tfalsepositive = len([1 for elem in zippedlist if elem == (True,False)])\n",
    "\tfalsenegative = len([1 for elem in zippedlist if elem == (False,True)])\n",
    "\tconf_matr = confusion_matrix(y_test, y_pred)\n",
    "\tplt.figure()\n",
    "\tplot_confusion_matrix(conf_matr, classes=class_names, normalize=True, title='Confusion matrix, normalized')\n",
    "\tplt.tight_layout(rect=(0,0,0.9,0.9))\n",
    "\tif not clfname is None:\n",
    "\t\tplt.savefig(clfname+\"-confusionmatrix.png\",format=\"png\")\n",
    "\tplt.show()\n",
    "\tif collect_infos:\n",
    "\t\tinfos.update({\"true positive\":truepositive, \"true negative\":truenegative,\n",
    "\t\t\t\t \"false positive\":falsepositive, \"false negative\":falsenegative})\n",
    "\taverage_precision = average_precision_score(y_test, y_pred)\n",
    "\tprecision_sc = precision_score(y_test, y_pred)\n",
    "\trecall_sc = recall_score(y_test, y_pred)\n",
    "\tprint(\"precision: {}, recall: {}\".format(precision_sc, recall_sc))\n",
    "\tprec, rec, thresh = precision_recall_curve(y_test, y_pred)\n",
    "\tplt.step(rec, prec, color='b', alpha=0.2, where='post')\n",
    "\tplt.fill_between(rec, prec, step='post', alpha=0.2, color='b')\n",
    "\tplt.xlabel('Recall')\n",
    "\tplt.ylabel('Precision')\n",
    "\tplt.ylim([0.0, 1.05])\n",
    "\tplt.xlim([0.0, 1.0])\n",
    "\tplt.title('2-class Precision-Recall curve: AP={0:0.2f}'.format(average_precision))\n",
    "\tplt.show()\n",
    "\tif collect_infos:\n",
    "\t\treturn fitclfscore, prec, rec, thresh, infos\n",
    "\treturn fitclfscore, prec, rec, thresh\n",
    "\n",
    "if TEST:\n",
    "\tknnscore = scoreclf(knnfitclf, (X_test, y_test))\n",
    "\trfscore = scoreclf(rffitclf, (X_test, y_test))\n",
    "\tabscore = scoreclf(abfitclf, (X_test, y_test))\n",
    "\tdtscore, dtprec, dtrec, dtthresh = scoreclf(dtfitclf, (X_test, y_test))\n",
    "\tmlpscore = scoreclf(mlpfitclf, (X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveobj(filename, ob):\n",
    "\twith open(filename, \"wb\") as outp:\n",
    "\t\tpickle.dump(ob, outp)\n",
    "\n",
    "if TEST:\n",
    "\tsaveobj(\"fitclf42.pk\", fitclf)\n",
    "\tsaveobj(\"fitclfscore42.pk\", fitclfscore1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classifier Read Eval Print Save\n",
    "def clfREPS(inpclf, inpdata=False, inpdatapath=csvpath, inp_version=global_version, collect_infos=False, overwrite=False, train_test_split_size=0.3, random_split=False, validation=False):\n",
    "\tif collect_infos:\n",
    "\t\tprint(\"collect_infos is now always on!\")\n",
    "\tif not inpdata:\n",
    "\t\t# load input data\n",
    "\t\tinpdata = csvImport(inpdatapath, wanted_version=inp_version, force_reload=False)\n",
    "\tdota_data = inpdata.get(\"data\")\n",
    "\tdota_target = inpdata.get(\"target\")\n",
    "\tlogger.debug(\"True:\",len([t for t in dota_target if t]),\"\\nFalse:\",len([t for t in dota_target if not t]))\n",
    "\tinfos={\"True/False ratio\":len([t for t in dota_target if t])/len([t for t in dota_target if not t]),\"data version\":inp_version, \"feature_names\":inpdata.feature_names}\n",
    "\tX_training, X_test, y_training, y_test = train_test_split(dota_data, dota_target, train_size=train_test_split_size, #random_state=42,\n",
    "\t\t\t\t\t\t\t shuffle=random_split)\n",
    "\tprintTrainTestSetShape(X_training, y_training)\n",
    "\tprintTrainTestSetShape(X_test, y_test)\n",
    "\tinfos.update({\"training size\":len(X_training), \"test size\":len(X_test)})\n",
    "\t# train classifier\n",
    "\tfitclf, newinfos = trainclf(inpclf, (X_training, y_training), collect_infos=True)\n",
    "\tinfos.update(newinfos)\n",
    "\t# evaluate, e.g. calculate f1 scores\n",
    "\tclffilename = \"{}-{}_{}\".format(re.split('\\(',str(fitclf))[0], inp_version, len(dota_data))\n",
    "\tfitclfscore, prec, rec, thresh, newinfos = scoreclf(fitclf, (X_test, y_test), collect_infos=True, class_names=inpdata[\"target_names\"], clfname=clffilename)\n",
    "\tif validation:\n",
    "\t\tcv = ShuffleSplit(n_splits=100, test_size=0.2, random_state=0)\n",
    "\t\tvalidation_plt = plot_learning_curve(inpclf, clffilename, dota_data, dota_target, ylim=(0.6,1.01), cv=cv, n_jobs=5)\n",
    "\t\tvalidation_plt.savefig(clffilename+\"validation.png\", format=\"png\")\n",
    "\t\tvalidation_plt.show()\n",
    "\tinfos.update(newinfos)\n",
    "\t# save classifier and score\n",
    "\tclfinfos = re.split('\\(',str(fitclf).strip('\\)'))\n",
    "\tproperties = re.sub('[\\n\\t\\ ]','',clfinfos[1])\n",
    "\tinfos.update({\"classifier\":re.split('\\(',str(fitclf))[0], \"clf params\":properties})\n",
    "\tif not os.path.isfile(clffilename+\".pickle\") or overwrite:\n",
    "\t\twith open(clffilename, \"wb\") as outp:\n",
    "\t\t\tpickle.dump((fitclf, infos), outp)\n",
    "\treturn fitclf, fitclfscore, infos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define classifiers to use for next cell\n",
    "classifiers = [\n",
    "\t\t\t  KNeighborsClassifier(),\n",
    "\t\t\t  AdaBoostClassifier(),\n",
    "\t\t\t  DecisionTreeClassifier(),\n",
    "\t\t\t  GradientBoostingClassifier(),\n",
    "\t\t\t  RandomForestClassifier(),\n",
    "\t\t\t  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this to get all the nice output, just remember to set the correct csvpath in the first cell\n",
    "inpd = csvImport(csvpath, wanted_version=inp_version, force_reload=False)\n",
    "for i, clf in enumerate(classifiers):\n",
    "\tfitclf, fitclfscore, infos = clfREPS(clf, inpd1, inp_version=inp_version, train_test_split_size=0.9, random_split=True)\n",
    "\tresultdict.update({infos[\"classifier\"]+inp_version:(fitclf, fitclfscore, infos)})\n",
    "for elem in zip(resultdict['DecisionTreeClassifier'+inp_version][2]['feature_names'],resultdict['DecisionTreeClassifier'+inp_version][0].feature_importances_):\n",
    "\tprint(elem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# superlambda to replace tick values with state point names\n",
    "def repltick(inp):\n",
    "\torig = inp.group(0)\n",
    "\tif orig == None:\n",
    "\t\treturn \"\"\n",
    "\tif orig == \"150\":\n",
    "\t\treturn \"p1\"\n",
    "\tif orig == \"180\":\n",
    "\t\treturn \"p2\"\n",
    "\tif orig == \"210\":\n",
    "\t\treturn \"p3\"\n",
    "\tif orig == \"240\":\n",
    "\t\treturn \"p4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create feature importance plots\n",
    "elist = [el for el in zip([re.sub(\"[0-9]*$\",repltick, e) for e in resultdict['DecisionTreeClassifier8e'][2]['feature_names']], resultdict['DecisionTreeClassifier8e'][0].feature_importances_)]\n",
    "elist.sort(key=lambda k:k[1])\n",
    "names, data = zip(*elist)\n",
    "fig, ax = plt.subplots(figsize=(8,8))\n",
    "ax.set_xlabel('feature importance')\n",
    "ax.set_ylabel('feature')\n",
    "ax.grid(True, axis='x')\n",
    "fig.tight_layout(rect=(0.2,0,0.95,1))\n",
    "ax.barh(names, data)\n",
    "#fig.savefig(\"dt-feature-importnce-plot.png\", format='png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elist = [el for el in zip([re.sub(\"[0-9]*$\",repltick, e) for e in resultdict['RandomForestClassifier8e'][2]['feature_names']], resultdict['RandomForestClassifier8e'][0].feature_importances_)]\n",
    "elist.sort(key=lambda k:k[1])#, reverse=True)\n",
    "names, data = zip(*elist)\n",
    "fig, ax = plt.subplots(figsize=(8,8))\n",
    "ax.set_xlabel('feature importance')\n",
    "ax.set_ylabel('feature')\n",
    "ax.grid(True, axis='x')\n",
    "fig.tight_layout(rect=(0.2,0,0.95,1))\n",
    "ax.barh(names, data)\n",
    "#fig.savefig(\"rf-feature-importance-plot.png\", format='png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elist = [el for el in zip([re.sub(\"[0-9]*$\",repltick, e) for e in resultdict['GradientBoostingClassifier8e'][2]['feature_names']], resultdict['GradientBoostingClassifier8e'][0].feature_importances_)]\n",
    "elist.sort(key=lambda k:k[1])\n",
    "names, data = zip(*elist)\n",
    "fig, ax = plt.subplots(figsize=(8,8))\n",
    "ax.set_xlabel('feature importance')\n",
    "ax.set_ylabel('feature')\n",
    "ax.grid(True, axis='x', )\n",
    "fig.tight_layout(rect=(0.2,0,0.95,1))\n",
    "ax.barh(names, data)\n",
    "#fig.savefig(\"gb-feature-importance-plot.png\", format='png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
